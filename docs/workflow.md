# Pipeline Workflow

Visual overview of the defect-detection pipeline. Use this for quick orientation and presentations.

PNG versions of these diagrams can be generated from the [flowchart_images](flowchart_images/) Mermaid sources (`.mmd`); run `python scripts/convert_mermaid_to_png.py docs/flowchart_images/ --all` (requires `@mermaid-js/mermaid-cli`).

## Single-frame pipeline

```mermaid
flowchart LR
    subgraph Input[" "]
        Img["ğŸ–¼ï¸ Image / Frame<br/>Camera, File, Stream"]
    end

    subgraph Preprocess["Preprocessing"]
        Resize["ğŸ“ Resize<br/>Model input size"]
        Normalize["ğŸ“Š Normalize<br/>e.g. 0â€“1"]
        Color["ğŸ¨ Color Convert<br/>e.g. BGRâ†’RGB"]
    end

    subgraph Inference["Inference"]
        Backend["âš¡ Inference Backend<br/>ONNX / TensorRT / Mock"]
        Decode["ğŸ” Defect Decoder<br/>Thresholds, NMS"]
    end

    subgraph Output[" "]
        Result["âœ… DefectResult<br/>frame_id, defects"]
        Alert["ğŸ“¢ Alerts / POS / Dashboard"]
    end

    Img --> Resize --> Normalize --> Color --> Backend --> Decode --> Result --> Alert
```

## End-to-end flow (with layers)

```mermaid
flowchart TD
    subgraph Sources["Input sources"]
        Cam["ğŸ“· Camera"]
        File["ğŸ“ Image file"]
        Stream["ğŸ“¡ Stream"]
    end

    Sources --> Frame["Frame<br/>width, height, format, buffer"]

    Frame --> Resize["ResizeStage<br/>ğŸ“ Target size"]
    Resize --> Normalize["NormalizeStage<br/>ğŸ“Š Mean/scale"]
    Normalize --> ColorConvert["ColorConvertStage<br/>ğŸ¨ Format for model"]
    ColorConvert --> DefectStage["DefectDetectionStage"]

    subgraph DefectStage["DefectDetectionStage"]
        Validate["validate_input()"]
        Infer["infer() / infer_batch()"]
        Decode["DefectDecoder"]
    end

    Validate --> Infer --> Decode

    Decode --> DefectResult["DefectResult<br/>frame_id, defects[]"]

    DefectResult --> App["Application layer"]
    App --> Log["Log / Store"]
    App --> Alert["Alert / POS"]
    App --> Report["Report / Dashboard"]

    classDef input fill:#e3f2fd,stroke:#1565c0
    classDef process fill:#f3e5f5,stroke:#7b1fa2
    classDef output fill:#e8f5e9,stroke:#2e7d32
    class Frame,Resize,Normalize,ColorConvert input
    class Validate,Infer,Decode,DefectStage process
    class DefectResult,Log,Alert,Report output
```

## Batch & parallel execution

```mermaid
flowchart TD
    Frames["ğŸ“¦ Batch of Frames"]
    Frames --> Choice{"Run mode?"}

    Choice -->|Sequential| Seq["run_pipeline_batch<br/>One frame after another"]
    Choice -->|Parallel| Par["run_pipeline_batch_parallel<br/>Thread pool, N workers"]

    Seq --> Run1["Pipeline::run(frameâ‚)"]
    Seq --> Run2["Pipeline::run(frameâ‚‚)"]
    Seq --> RunN["Pipeline::run(frameâ‚™)"]

    Par --> Pool["Worker 1 â€¦ Worker N"]
    Pool --> RunP1["Pipeline::run(frame)"]
    Pool --> RunP2["Pipeline::run(frame)"]

    Run1 --> CB["Callback(DefectResult)"]
    Run2 --> CB
    RunN --> CB
    RunP1 --> CB
    RunP2 --> CB

    CB --> Out["Collect / Alert / Store"]
```

## Where to extend

| Extension point | What to add |
|-----------------|-------------|
| **Image source** | New input (camera, MQTT, etc.) â†’ produce `Frame` |
| **Preprocessing** | New stage implementing `IPipelineStage` (e.g. crop, augment) |
| **Inference** | New backend implementing `IInferenceBackend` (e.g. ONNX Runtime) |
| **Output** | New consumer of `DefectResult` (e.g. REST API, metrics) |

See [Architecture](architecture.md) and [API Reference](api-reference.md) for details.
